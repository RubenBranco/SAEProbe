{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "from sae.anthropic import SAEConfig, SAEPLDataset, SAEPLModel\n",
    "from sae.hooks import RecordingHookPoint\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jaxtyping\n",
    "%jaxtyping.typechecker typeguard.typechecked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following taken from https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                ),\n",
    "                end=\"\\r\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efb8da9d390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n",
    "dataset2 = datasets.MNIST(\"../data\", train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {\n",
    "    \"batch_size\": 64,\n",
    "    \"num_workers\": cpu_count(),\n",
    "    \"shuffle\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [57600/60000 (96%)]\tLoss: 0.013999\r"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, torch.optim.Adam(model.parameters()), epoch, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_fc1 = RecordingHookPoint(model, \"fc1\")\n",
    "hook_fc2 = RecordingHookPoint(model, \"fc2\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset1, batch_size=128, num_workers=cpu_count(), shuffle=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset2, batch_size=128, num_workers=cpu_count(), shuffle=False\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, _ in train_loader:\n",
    "        img = img.to(device)\n",
    "        model(img)\n",
    "        del img\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "train_fc1_activations = torch.cat(hook_fc1.activation_store)\n",
    "train_fc2_activations = torch.cat(hook_fc2.activation_store)\n",
    "\n",
    "hook_fc1.reset_activation_store()\n",
    "hook_fc2.reset_activation_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for img, _ in test_loader:\n",
    "        img = img.to(device)\n",
    "        model(img)\n",
    "        del img\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "test_fc1_activations = torch.cat(hook_fc1.activation_store)\n",
    "test_fc2_activations = torch.cat(hook_fc2.activation_store)\n",
    "\n",
    "hook_fc1.close()\n",
    "hook_fc2.close()\n",
    "\n",
    "del hook_fc1\n",
    "del hook_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_config = SAEConfig(\n",
    "    input_dim=train_fc1_activations.size(1), latent_dim=2**15, batch_size=512, sparsity_coefficient=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_fc1 = SAEPLModel(sae_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_steps=100000,\n",
    "    accelerator=\"gpu\",\n",
    "    logger=False,\n",
    "    enable_checkpointing=False,\n",
    "    gradient_clip_val=1.0,\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SAEPLDataset(\n",
    "    torch.cat([train_fc1_activations, test_fc1_activations]), sae_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params | Mode \n",
      "--------------------------------------\n",
      "0 | sae  | SAE  | 8.4 M  | train\n",
      "--------------------------------------\n",
      "8.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.4 M     Total params\n",
      "33.686    Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▏         | 2/124 [00:00<00:12,  9.50it/s, train/loss=0.957, train/loss_mse=0.957, train/loss_sparsity=0.000, lr=5e-5, sparsity_coefficient=4e-5, dead_neurons=0.000, train/firing_rate=1.91e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rubenbranco/miniconda3/envs/saeprob/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:212: You called `self.log('dead_neurons', ...)` in your `training_step` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'dead_neurons': ...})` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 806:  45%|████▌     | 56/124 [00:00<00:00, 144.47it/s, train/loss=0.657, train/loss_mse=0.657, train/loss_sparsity=0.000942, lr=2.5e-9, sparsity_coefficient=0.200, dead_neurons=30426.0, train/firing_rate=0.102, val/loss=0.649, val/loss_mse=0.646, val/loss_sparsity=0.00284]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 806:  45%|████▌     | 56/124 [00:00<00:00, 144.24it/s, train/loss=0.657, train/loss_mse=0.657, train/loss_sparsity=0.000942, lr=2.5e-9, sparsity_coefficient=0.200, dead_neurons=30426.0, train/firing_rate=0.102, val/loss=0.649, val/loss_mse=0.646, val/loss_sparsity=0.00284]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(sae_fc1, datamodule=ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saeprob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
